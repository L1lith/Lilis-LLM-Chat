# Lili's LLM Chat App
Why might my LLM chat app be perfect for you?  
If you like any of these features then please consider giving it a chance:

*   Easy to use & 1 click install
*   Free & Open Source
*   Supports enhanced data privacy
*   Beautiful UI
*   Works with any LLM that has an API
*   Available on Windows, Linux, and Mac
*   Access to more environmentally friendly AIs

Download
--------

*   [Linux](https://github.com/L1lith/Lilis-LLM-Chat/releases/download/v1.1.0/lilis-llm-chat-1.1.0-x86_64.AppImage)
*   [Windows](https://github.com/L1lith/Lilis-LLM-Chat/releases/download/v1.1.0/lilis-llm-chat-setup-1.1.0.exe)
*   [macOS](https://github.com/L1lith/Lilis-LLM-Chat/releases/download/v1.1.0/lilis-llm-chat-1.1.0.dmg)

![](https://github.com/L1lith/Lilis-LLM-Chat/blob/main/readme-assets/lilis-llm-ui-preview.JPG)

Your app, your data.
--------------------
  
Lili's LLM Studio stores all of your data on your local device, it doesn't give me any access to your data. Furthermore, you can use it with any AI you want (as long as it has an API) so it always be will be there for you even when you wanna switch AIs. I love the freedom I get from being able to choose from any AI I want. There are so many options, including more eco friendly AIs or AIs that have better privacy policies like those provided by [Together.ai](https://www.together.ai/) (not sponsored or affiliated) which I prefer to use. You can connect to your own AIs running locally by pairing it with LM Studio.

This app could be your chance to try out new AIs (be them better, more eco-friendly, or both). Big corporate AI companies like OpenAI (the creators of ChatGPT) not only want to own your data, but profit off of you being trapped in to their ecosystem! My app is designed so your interface and your data stays yours. 


Building
--------
If you'd like to build this app on your local device you can do so using the commands in the terminal of your choice, assuming you have nodejs and git installed:
1. clone the repo `git clone https://github.com/L1lith/Lilis-LLM-Chat`
2. cd into the directory `cd Lilis-LLM-Chat`
3. install the npm dependencies `npm install`
4. build the app `npm run build`

The app will be build and available in the `dist-electron` subdirectory

*Sleek.*
------

Also, my code is much sleeker than the competition. If you exclude non-code files (like svgs and JSON) my project comes out to ~1816 lines of code, compared to Open WebUI's ~193577 lines of code (according to codetabs.com). While my app doesn't have quite as many features, it's still fully functioning while using ~100x less code. This meticulous design at every step of the way enables me to provide you with a very finely tuned user experience.

### Lili's LLM Chat Size
![](https://github.com/L1lith/Lilis-LLM-Chat/blob/main/readme-assets/lilis-llm-loc.JPG) 
#### **- VS -**
### Open WebUI Size
![](https://github.com/L1lith/Lilis-LLM-Chat/blob/main/readme-assets/open-webui-loc.JPG)

Links
-----
*   [Support Me](https://webslc.com/links)